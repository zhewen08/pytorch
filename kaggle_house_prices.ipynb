{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a88e63-2cb5-40e0-b780-e3dd5a25d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes\n",
    "# 1. Use Pandas to pre-process data\n",
    "# 2. Process special columns i.e. id and label separately from features\n",
    "# 3. Normalize/transform features and label separately. Transform label\n",
    "#    simply so that it's easier to restore predicted label in the \n",
    "#    original scale\n",
    "# 4. Test set may have different features in one-hot encoding because\n",
    "#    string values (vocabulary) in test set is likely a little different\n",
    "#    from train set. Create new df of train columns to prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc50ccec-6358-47a8-9892-dbe77da48906",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data, cut a sandbox fraction. Do NOT run unless\n",
    "# you want to change the data used.\n",
    "\n",
    "# data_path = 'data/california-house-prices'\n",
    "# train_path = os.path.join(data_path, 'train.csv')\n",
    "# test_path = os.path.join(data_path, 'test.csv')\n",
    "# sb_train_path = os.path.join(data_path, 'train_sb.csv')\n",
    "# sb_test_path = os.path.join(data_path, 'test_sb.csv')\n",
    "# \n",
    "# train = pd.read_csv(train_path)\n",
    "# sb_train = train.sample(frac=0.1)\n",
    "# test = pd.read_csv(test_path)\n",
    "# sb_test = test.sample(frac=0.1)\n",
    "# sb_train.to_csv(sb_train_path)\n",
    "# sb_test.to_csv(sb_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367d027a-678f-47f9-9cee-56b791315ece",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37951 entries, 13470 to 44438\n",
      "Columns: 936 entries, Id to State_CA\n",
      "dtypes: float64(4), int64(1), uint8(931)\n",
      "memory usage: 35.4 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9488 entries, 9 to 47438\n",
      "Columns: 936 entries, Id to State_CA\n",
      "dtypes: float64(4), int64(1), uint8(931)\n",
      "memory usage: 8.9 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process data\n",
    "\n",
    "# Special columns\n",
    "case = ['Id']\n",
    "label = ['Sold Price']\n",
    "specials = case + label\n",
    "# Sandbox features\n",
    "features = [\n",
    "    'Total interior livable area',\n",
    "    'Tax assessed value',\n",
    "    'Listed Price',\n",
    "    'City',\n",
    "    'State',\n",
    "]\n",
    "\n",
    "columns = specials + features\n",
    "\n",
    "data_path = 'data/california-house-prices'\n",
    "train_data_path = os.path.join(data_path, 'train.csv')\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "\n",
    "# test.cvs is for submission\n",
    "# sb_test_path = os.path.join(data_path, 'test_sb.csv')\n",
    "# test = pd.read_csv(sb_test_path)\n",
    "\n",
    "def fill_mean_(df):\n",
    "    # Check which column has any NaN value\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype not in ['int', 'float']:\n",
    "            continue\n",
    "        if df[c].isnull().any(axis=0):\n",
    "            df[c].fillna(df[c].mean(), inplace=True)\n",
    "            \n",
    "def fill_zero_(df):\n",
    "    # Check which column has any NaN value\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype not in ['int', 'float']:\n",
    "            continue\n",
    "        if df[c].isnull().any(axis=0):\n",
    "            df[c].fillna(0, inplace=True)\n",
    "\n",
    "def zscore_(df):\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype not in ['int', 'float']:\n",
    "            continue\n",
    "        df[c] = (df[c] - df[c].mean()) / df[c].std()\n",
    "        \n",
    "def transform(df, test=False):\n",
    "    if test:\n",
    "        fill_zero_(df)\n",
    "    else:\n",
    "        fill_mean_(df)\n",
    "    zscore_(df)\n",
    "    return pd.get_dummies(df)\n",
    "\n",
    "# Label in first column\n",
    "train_specials = train_data.loc[:, specials]\n",
    "train_features = transform(train_data.loc[:, features])\n",
    "# col1: Id, col2: Label (Sold Price), col rest: features\n",
    "train_df = pd.concat([train_specials, train_features], axis=1)\n",
    "train = train_df.sample(frac=0.8, random_state=1)\n",
    "test = train_df.drop(train.index)\n",
    "\n",
    "# Int64Index: 3795 entries, 1642 to 185\n",
    "# Columns: 501 entries, Sold Price to State_CA\n",
    "# dtypes: float64(4), uint8(497)\n",
    "# memory usage: 2.1 MB\n",
    "train.info(), test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd7317c1-8558-4cf1-8dda-4ed668ee27f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train classes\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class HousePriceDataset(data.Dataset):\n",
    "    def __init__(self, annotated_df, transform=None, \n",
    "                 target_transform=None):\n",
    "        self.examples = annotated_df\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.examples.iloc[idx]\n",
    "        # col1: Id, col2: Label (Sold Price), col rest: features\n",
    "        X = torch.from_numpy(example[2:].values).float()\n",
    "        y = torch.from_numpy(example[1:2].values).float()\n",
    "        \n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        if self.target_transform:\n",
    "            y = self.target_transform(y)\n",
    "            \n",
    "        return X, y\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HousePriceNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        num_inputs = 934\n",
    "        num_hiddens1 = 384\n",
    "        num_outputs = 1\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hiddens1)\n",
    "        nn.init.normal_(self.linear1.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(self.linear1.bias)\n",
    "        self.linear2 = nn.Linear(num_hiddens1, num_outputs)\n",
    "        nn.init.normal_(self.linear2.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(self.linear2.bias)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # self.verbose()\n",
    "        X = self.linear1(X)\n",
    "        X = self.relu(X)\n",
    "        return self.linear2(X)\n",
    "    \n",
    "    def verbose(self):\n",
    "        for p in self.linear1.parameters():\n",
    "            print(\"linear1 max min\\n\", p.max(), p.min())\n",
    "            if p.grad is not None:\n",
    "                print(\"linear1 grad max min\\n\", p.grad.max(), p.grad.min())\n",
    "        for p in self.linear2.parameters():\n",
    "            print(\"linear2 max min\\n\", p.max(), p.min())\n",
    "            if p.grad is not None:\n",
    "                print(\"linear2 grad max min\\n\", p.grad.max(), p.grad.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97d91197-0da1-4a72-9a0c-a4b050ce9d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 9, train loss 0.001523\n",
      "batch 18, train loss 0.001297\n",
      "batch 27, train loss 0.001184\n",
      "batch 36, train loss 0.001122\n",
      "batch 45, train loss 0.001081\n",
      "batch 54, train loss 0.001051\n",
      "batch 63, train loss 0.001030\n",
      "batch 72, train loss 0.001016\n",
      "epoch 0, train loss 0.001025, test loss 0.000934\n",
      "batch 9, train loss 0.000898\n",
      "batch 18, train loss 0.000898\n",
      "batch 27, train loss 0.000902\n",
      "batch 36, train loss 0.000905\n",
      "batch 45, train loss 0.000903\n",
      "batch 54, train loss 0.000901\n",
      "batch 63, train loss 0.000899\n",
      "batch 72, train loss 0.000899\n",
      "epoch 1, train loss 0.000911, test loss 0.000918\n",
      "batch 9, train loss 0.000871\n",
      "batch 18, train loss 0.000882\n",
      "batch 27, train loss 0.000885\n",
      "batch 36, train loss 0.000885\n",
      "batch 45, train loss 0.000888\n",
      "batch 54, train loss 0.000885\n",
      "batch 63, train loss 0.000884\n",
      "batch 72, train loss 0.000882\n",
      "epoch 2, train loss 0.000889, test loss 0.000897\n",
      "batch 9, train loss 0.000864\n",
      "batch 18, train loss 0.000868\n",
      "batch 27, train loss 0.000862\n",
      "batch 36, train loss 0.000874\n",
      "batch 45, train loss 0.000871\n",
      "batch 54, train loss 0.000861\n",
      "batch 63, train loss 0.000861\n",
      "batch 72, train loss 0.000859\n",
      "epoch 3, train loss 0.000868, test loss 0.000867\n",
      "batch 9, train loss 0.000851\n",
      "batch 18, train loss 0.000840\n",
      "batch 27, train loss 0.000838\n",
      "batch 36, train loss 0.000847\n",
      "batch 45, train loss 0.000841\n",
      "batch 54, train loss 0.000835\n",
      "batch 63, train loss 0.000832\n",
      "batch 72, train loss 0.000830\n",
      "epoch 4, train loss 0.000840, test loss 0.000831\n"
     ]
    }
   ],
   "source": [
    "# Train process\n",
    "\n",
    "def train_epoch(net, train_iter, loss, updater):\n",
    "    train_l = 0\n",
    "    b = 0\n",
    "    train_cnt = 0\n",
    "    for X, y in train_iter:\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y).sum()\n",
    "        train_l += l\n",
    "        updater.zero_grad()\n",
    "        l.backward()\n",
    "        updater.step()\n",
    "        b += 1\n",
    "        train_cnt += y.numel()\n",
    "        if b % 9 == 0:\n",
    "            print(f\"batch {b}, train loss {train_l/train_cnt:8f}\")\n",
    "        \n",
    "    return train_l / len(train_iter.dataset)\n",
    "\n",
    "def validate(net, test_iter, loss):\n",
    "    test_l = 0\n",
    "    with torch.no_grad():\n",
    "        for X, trues in test_iter:\n",
    "            preds = net(X)\n",
    "            test_l += loss(preds, trues).sum()\n",
    "\n",
    "    return test_l / len(test_iter.dataset)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def y_transform(y):\n",
    "    return y / 1000000\n",
    "\n",
    "def rmse(y_hat, y):\n",
    "    mse = nn.MSELoss()\n",
    "    # print(torch.cat([y_hat, y, (y_hat - y) / y], axis=1))\n",
    "    return mse((y_hat - y) / y, torch.zeros_like(y))\n",
    "\n",
    "batch_size = 512\n",
    "train_dataset = HousePriceDataset(train, target_transform=y_transform)\n",
    "train_iter = data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataset = HousePriceDataset(test, target_transform=y_transform)\n",
    "test_iter = data.DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "net = HousePriceNet()\n",
    "loss = rmse\n",
    "lr = 0.008\n",
    "updater = torch.optim.SGD(net.parameters(), lr)\n",
    "\n",
    "epoch = 5\n",
    "for e in range(epoch):\n",
    "    train_loss = train_epoch(net, train_iter, loss, updater)\n",
    "    test_loss = validate(net, test_iter, loss)\n",
    "    print(f\"epoch {e}, train loss {train_loss:8f}, test loss {test_loss:8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fc21342-774e-4da6-9bcd-a493861d499e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model in case kernel crashes\n",
    "model_path = os.path.join(data_path, 'v2.model')\n",
    "torch.save(net.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c22c2a40-b2cb-489e-b17b-41f47c946917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepared test.csv for submission\n",
    "sub_data_path = os.path.join(data_path, 'test.csv')\n",
    "sub_data = pd.read_csv(sub_data_path)\n",
    "\n",
    "sub_df_specials = sub_data.loc[:, case]\n",
    "sub_df_specials[label] = 0\n",
    "# This step transforms string data to one-hot encoding\n",
    "# Some string value in submission set does not exist in\n",
    "# training set i.e. this example does not have a feature\n",
    "# We need to take training features, fill up those the\n",
    "# test example has, and the rest zero.\n",
    "sub_df_features = transform(sub_data.loc[:, features])\n",
    "\n",
    "def prepare(input, cols):\n",
    "    output = pd.DataFrame(columns=cols)\n",
    "    for c in output.columns:\n",
    "        if c in input.columns:\n",
    "            output[c] = input[c]\n",
    "        else:\n",
    "            output[c] = 0\n",
    "    return output\n",
    "\n",
    "available_features = train_features.columns\n",
    "sub_df_features = prepare(sub_df_features, available_features)\n",
    "\n",
    "sub_df = pd.concat([sub_df_specials, sub_df_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b7f57b5-f637-49f2-b138-c35be1ed7a98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model for predicting\n",
    "model_path = os.path.join(data_path, 'v2.model')\n",
    "net = HousePriceNet()\n",
    "net.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d17ec35b-0297-43c9-8970-309d0acafdf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do actual precition\n",
    "sub_batch_size = 1000\n",
    "sub_dataset = HousePriceDataset(sub_df)\n",
    "sub_iter = data.DataLoader(sub_dataset, sub_batch_size, shuffle=False)\n",
    "\n",
    "def predict(net, sub_iter):\n",
    "    net.eval()\n",
    "    results = torch.Tensor([])\n",
    "    for X, _ in sub_iter:\n",
    "        preds = net(X) * 1000000\n",
    "        results = torch.cat((results, preds), dim=0)\n",
    "    return results\n",
    "\n",
    "preds = predict(net, sub_iter)\n",
    "preds_df = pd.DataFrame(data=preds.detach().numpy(), columns=['Sold Price'])\n",
    "\n",
    "submission = pd.concat([sub_df['Id'], preds_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "918f0103-132b-44cf-a19a-edae984e60dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_results_path = os.path.join(data_path, 'v2_results.csv')\n",
    "submission.to_csv(sub_results_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d689b84c-b8c3-491e-9443-85b057a73320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_info = '''\n",
    "Loss.\n",
    "    Use relative price difference (rmse) loss hence not directly\n",
    "    comparable to v0 v1 loss (mse)\n",
    "Features used.\n",
    "    'Total interior livable area',\n",
    "    'Tax assessed value',\n",
    "    'Listed Price',\n",
    "    'City',\n",
    "    'State',\n",
    "Train data set.\n",
    "    1.0 frac train.csv used in training.\n",
    "    0.8 frac training data used for training, 0.2 for validation\n",
    "    1.0 frac test.csv used in submission.\n",
    "Loss.\n",
    "    batch_size 512\n",
    "    learning rate 0.008\n",
    "    epochs 5\n",
    "    epoch 4, train loss 0.000840, test loss 0.000831\n",
    "Public score. 0.75984\n",
    "Private score. 0.76469\n",
    "'''\n",
    "model_info_path = os.path.join(data_path, 'v1.info')\n",
    "with open(model_info_path, 'w') as fd:\n",
    "    fd.write(model_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
